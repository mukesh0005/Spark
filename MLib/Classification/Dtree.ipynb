{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"DecisionTreeTuning\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(0, 2.0, 1.0, 1.0), (1, 3.0, 2.0, 0.0), (0, 4.0, 3.0, 0.0), (1, 5.0, 4.0, 1.0)]\n",
    "columns = [\"label\", \"feature1\", \"feature2\", \"feature3\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\", \"feature3\"], outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Create decision tree classifier\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [2, 3, 4]) \\\n",
    "    .addGrid(dt.minInstancesPerNode, [1, 2, 3]) \\\n",
    "    .build()\n",
    "\n",
    "# Create cross-validator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=dt,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3)\n",
    "\n",
    "# Run cross-validation\n",
    "cvModel = cv.fit(df)\n",
    "\n",
    "# Get best model from cross-validation\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "# Make predictions using the best model\n",
    "predictions = bestModel.transform(df)\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show()\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
